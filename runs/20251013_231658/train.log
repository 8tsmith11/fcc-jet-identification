[iter 0001] loss=0.96587214
[iter 0002] loss=0.97367728
[iter 0003] loss=0.94186347
[iter 0004] loss=0.91978655
[iter 0005] loss=0.92281563
[iter 0006] loss=0.91325379
[iter 0007] loss=0.91214155
[iter 0008] loss=0.89336522
[iter 0009] loss=0.95437683
[iter 0010] loss=0.91332265
[iter 0011] loss=0.89405624
[iter 0012] loss=0.87391122
[iter 0013] loss=0.88539830
[iter 0014] loss=0.86788310
[iter 0015] loss=0.86984629
[iter 0016] loss=0.87151483
[iter 0017] loss=0.85810872
[iter 0018] loss=0.88216347
[iter 0019] loss=0.87647462
[iter 0020] loss=0.84864316
[iter 0021] loss=0.82560575
[iter 0022] loss=0.88689029
[iter 0023] loss=0.84499969
[iter 0024] loss=0.84487793
[iter 0025] loss=0.85042993
[iter 0026] loss=0.92486393
[iter 0027] loss=0.87648058
[iter 0028] loss=0.93674092
[iter 0029] loss=0.82168825
[iter 0030] loss=0.85199540
[iter 0031] loss=0.78896101
[iter 0032] loss=0.79048464
[iter 0033] loss=0.91059199
[iter 0034] loss=0.90268791
[iter 0035] loss=0.76734334
[iter 0036] loss=0.79484612
[iter 0037] loss=0.74652611
[iter 0038] loss=0.74650259
[iter 0039] loss=0.87243092
[iter 0040] loss=1.00359348
[iter 0041] loss=0.74474377
[iter 0042] loss=0.86964529
[iter 0043] loss=0.99915047
[iter 0044] loss=0.74633022
[iter 0045] loss=0.74924637
[iter 0046] loss=0.74575113
[iter 0047] loss=0.74667111
[iter 0048] loss=0.74793872
[iter 0049] loss=0.74901959
[iter 0050] loss=0.79776581
[iter 0051] loss=0.80794453
[iter 0052] loss=0.79073825
[iter 0053] loss=0.75819244
[iter 0054] loss=0.69616583
[iter 0055] loss=0.77845622
[iter 0056] loss=0.69521274
[iter 0057] loss=0.69666286
[iter 0058] loss=0.69062079
[iter 0059] loss=0.72438788
[iter 0060] loss=0.82192258
[iter 0061] loss=0.89094546
[iter 0062] loss=0.70032389
[iter 0063] loss=0.80572233
[iter 0064] loss=0.92651148
[iter 0065] loss=0.81708282
[iter 0066] loss=0.71142463
[iter 0067] loss=0.82394537
[iter 0068] loss=0.72023829
[iter 0069] loss=0.82755339
[iter 0070] loss=0.71764389
[iter 0071] loss=0.73696455
[iter 0072] loss=0.71207815
[iter 0073] loss=0.70880267
[iter 0074] loss=0.71384238
[iter 0075] loss=0.70272127
[iter 0076] loss=0.71043509
[iter 0077] loss=0.79601035
[iter 0078] loss=0.68196946
[iter 0079] loss=0.69994845
[iter 0080] loss=0.68320172
[iter 0081] loss=0.68791770
[iter 0082] loss=0.71744135
[iter 0083] loss=0.75978496
[iter 0084] loss=0.71533519
[iter 0085] loss=0.69665590
[iter 0086] loss=0.67870997
[iter 0087] loss=0.82612191
[iter 0088] loss=0.71285134
[iter 0089] loss=0.69673745
[iter 0090] loss=0.70074061
[iter 0091] loss=0.69992887
[iter 0092] loss=0.70674039
[iter 0093] loss=0.76976078
[iter 0094] loss=0.71846349
[iter 0095] loss=0.79204870
[iter 0096] loss=0.78168028
[iter 0097] loss=0.76010202
[iter 0098] loss=0.72433764
[iter 0099] loss=0.75900884
[iter 0100] loss=0.68865629
[iter 0101] loss=0.67640741
[iter 0102] loss=0.68205486
[iter 0103] loss=0.78231290
[iter 0104] loss=0.67742052
[iter 0105] loss=0.73871211
[iter 0106] loss=0.66528728
[iter 0107] loss=0.81766565
[iter 0108] loss=0.69272539
[iter 0109] loss=0.69716496
[iter 0110] loss=0.68270987
[iter 0111] loss=0.72666372
[iter 0112] loss=0.65972292
[iter 0113] loss=0.70673392
[iter 0114] loss=0.66298054
[iter 0115] loss=0.69504156
[iter 0116] loss=0.66477363
[iter 0117] loss=0.84668937
[iter 0118] loss=0.66410599
[iter 0119] loss=0.77158568
[iter 0120] loss=0.66384612
[iter 0121] loss=0.68370751
[iter 0122] loss=0.66139613
[iter 0123] loss=0.72050466
[iter 0124] loss=0.66248368
[iter 0125] loss=0.87809893
[iter 0126] loss=0.67488004
[iter 0127] loss=0.87668288
[iter 0128] loss=0.69972052
[iter 0129] loss=0.72960660
[iter 0130] loss=0.68098880
[iter 0131] loss=0.69418523
[iter 0132] loss=0.69630635
[iter 0133] loss=0.78931315
[iter 0134] loss=0.67836901
[iter 0135] loss=0.72889630
[iter 0136] loss=0.68352773
[iter 0137] loss=0.70105236
[iter 0138] loss=0.65716979
[iter 0139] loss=0.66074205
[iter 0140] loss=0.68970326
[iter 0141] loss=0.65487242
[iter 0142] loss=0.66780905
[iter 0143] loss=0.66021635
[iter 0144] loss=0.67818661
[iter 0145] loss=0.63379378
[iter 0146] loss=0.65489056
[iter 0147] loss=0.63957339
[iter 0148] loss=0.65339634
[iter 0149] loss=0.62099600
[iter 0150] loss=0.64541987
[iter 0151] loss=0.62300055
[iter 0152] loss=0.62807941
[iter 0153] loss=0.61935996
[iter 0154] loss=0.63626005
[iter 0155] loss=0.61537137
[iter 0156] loss=0.60930654
[iter 0157] loss=0.61041584
[iter 0158] loss=0.62239820
[iter 0159] loss=0.62471734
[iter 0160] loss=0.62871591
[iter 0161] loss=0.61929322
[iter 0162] loss=0.67673340
[iter 0163] loss=0.61943707
[iter 0164] loss=0.64388712
[iter 0165] loss=0.61576077
[iter 0166] loss=0.61696603
[iter 0167] loss=0.61843814
[iter 0168] loss=0.65020480
[iter 0169] loss=0.60107718
[iter 0170] loss=0.62466437
[iter 0171] loss=0.61901597
[iter 0172] loss=0.62727773
[iter 0173] loss=0.60647926
[iter 0174] loss=0.60051244
[iter 0175] loss=0.59309647
[iter 0176] loss=0.58483642
[iter 0177] loss=0.58889627
[iter 0178] loss=0.60891862
[iter 0179] loss=0.59719582
[iter 0180] loss=0.61678244
[iter 0181] loss=0.58756836
[iter 0182] loss=0.56817438
[iter 0183] loss=0.54818185
[iter 0184] loss=0.58175069
[iter 0185] loss=0.54367318
[iter 0186] loss=0.55720395
[iter 0187] loss=0.55050359
[iter 0188] loss=0.55463718
[iter 0189] loss=0.56019279
[iter 0190] loss=0.58795682
[iter 0191] loss=0.54534811
[iter 0192] loss=0.54790545
[iter 0193] loss=0.56890937
[iter 0194] loss=0.52182960
[iter 0195] loss=0.51939626
[iter 0196] loss=0.52191327
[iter 0197] loss=0.52202732
[iter 0198] loss=0.51318374
[iter 0199] loss=0.52040017
[iter 0200] loss=0.51681149
Accuracy from the train data : 91.43%
Accuracy from the test data : 90.0%
Saved classifier to runs/20251013_231658/classifier.model
Saved objective curve to runs/20251013_231658/objective_curve.png
